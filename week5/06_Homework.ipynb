{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c983bbb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/03/30 20:29:13 WARN SparkContext: Another SparkContext is being constructed (or threw an exception in its constructor). This may indicate an error, since only one SparkContext should be running in this JVM (see SPARK-2243). The other SparkContext was created at:\n",
      "org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)\n",
      "java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)\n",
      "py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)\n",
      "py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "py4j.Gateway.invoke(Gateway.java:238)\n",
      "py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)\n",
      "py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)\n",
      "py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "java.base/java.lang.Thread.run(Thread.java:834)\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"spark://instance-1.us-west1-b.c.forward-ace-411913.internal:7077\") \\\n",
    "    .appName('spark_homework') \\\n",
    "    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "5fb212af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.3.2'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4260aecf",
   "metadata": {},
   "outputs": [],
   "source": [
    " import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4e9ea565",
   "metadata": {},
   "outputs": [],
   "source": [
    " pdf= pd.read_csv('data/raw/fhv/fhv_tripdata_2019-10.csv.gz',compression='gzip' , nrows=1000)\n",
    "#pdf.iteritems =pdf.items   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "744c8167",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dispatching_base_num</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropOff_datetime</th>\n",
       "      <th>PUlocationID</th>\n",
       "      <th>DOlocationID</th>\n",
       "      <th>SR_Flag</th>\n",
       "      <th>Affiliated_base_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B00009</td>\n",
       "      <td>2019-10-01 00:23:00</td>\n",
       "      <td>2019-10-01 00:35:00</td>\n",
       "      <td>264.0</td>\n",
       "      <td>264.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B00009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B00013</td>\n",
       "      <td>2019-10-01 00:11:29</td>\n",
       "      <td>2019-10-01 00:13:22</td>\n",
       "      <td>264.0</td>\n",
       "      <td>264.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B00013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B00014</td>\n",
       "      <td>2019-10-01 00:11:43</td>\n",
       "      <td>2019-10-01 00:37:20</td>\n",
       "      <td>264.0</td>\n",
       "      <td>264.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B00014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B00014</td>\n",
       "      <td>2019-10-01 00:56:29</td>\n",
       "      <td>2019-10-01 00:57:47</td>\n",
       "      <td>264.0</td>\n",
       "      <td>264.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B00014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B00014</td>\n",
       "      <td>2019-10-01 00:23:09</td>\n",
       "      <td>2019-10-01 00:28:27</td>\n",
       "      <td>264.0</td>\n",
       "      <td>264.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B00014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>B00111</td>\n",
       "      <td>2019-10-01 01:54:57</td>\n",
       "      <td>2019-10-01 03:10:06</td>\n",
       "      <td>264.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B00111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>B00111</td>\n",
       "      <td>2019-10-01 01:07:06</td>\n",
       "      <td>2019-10-01 01:29:54</td>\n",
       "      <td>264.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B00111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>B00112</td>\n",
       "      <td>2019-10-01 01:05:36</td>\n",
       "      <td>2019-10-01 01:36:28</td>\n",
       "      <td>264.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B00112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>B00160</td>\n",
       "      <td>2019-10-01 01:20:00</td>\n",
       "      <td>2019-10-01 01:26:00</td>\n",
       "      <td>264.0</td>\n",
       "      <td>264.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B00160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>B00225</td>\n",
       "      <td>2019-10-01 01:15:03</td>\n",
       "      <td>2019-10-01 01:22:57</td>\n",
       "      <td>264.0</td>\n",
       "      <td>232.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B00225</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    dispatching_base_num      pickup_datetime     dropOff_datetime  \\\n",
       "0                 B00009  2019-10-01 00:23:00  2019-10-01 00:35:00   \n",
       "1                 B00013  2019-10-01 00:11:29  2019-10-01 00:13:22   \n",
       "2                 B00014  2019-10-01 00:11:43  2019-10-01 00:37:20   \n",
       "3                 B00014  2019-10-01 00:56:29  2019-10-01 00:57:47   \n",
       "4                 B00014  2019-10-01 00:23:09  2019-10-01 00:28:27   \n",
       "..                   ...                  ...                  ...   \n",
       "995               B00111  2019-10-01 01:54:57  2019-10-01 03:10:06   \n",
       "996               B00111  2019-10-01 01:07:06  2019-10-01 01:29:54   \n",
       "997               B00112  2019-10-01 01:05:36  2019-10-01 01:36:28   \n",
       "998               B00160  2019-10-01 01:20:00  2019-10-01 01:26:00   \n",
       "999               B00225  2019-10-01 01:15:03  2019-10-01 01:22:57   \n",
       "\n",
       "     PUlocationID  DOlocationID  SR_Flag Affiliated_base_number  \n",
       "0           264.0         264.0      NaN                 B00009  \n",
       "1           264.0         264.0      NaN                 B00013  \n",
       "2           264.0         264.0      NaN                 B00014  \n",
       "3           264.0         264.0      NaN                 B00014  \n",
       "4           264.0         264.0      NaN                 B00014  \n",
       "..            ...           ...      ...                    ...  \n",
       "995         264.0         100.0      NaN                 B00111  \n",
       "996         264.0         188.0      NaN                 B00111  \n",
       "997         264.0         228.0      NaN                 B00112  \n",
       "998         264.0         264.0      NaN                 B00160  \n",
       "999         264.0         232.0      NaN                 B00225  \n",
       "\n",
       "[1000 rows x 7 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b9e1baca",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf.Affiliated_base_number = pdf.Affiliated_base_number.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0b6e20b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('dispatching_base_num', StringType(), True), StructField('pickup_datetime', StringType(), True), StructField('dropOff_datetime', StringType(), True), StructField('PUlocationID', DoubleType(), True), StructField('DOlocationID', DoubleType(), True), StructField('SR_Flag', DoubleType(), True), StructField('Affiliated_base_number', StringType(), True)])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.createDataFrame(pdf).schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2f09c9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import types\n",
    "schema = types.StructType([\n",
    "    types.StructField('dispatching_base_num', types.StringType(), True)\n",
    "    , types.StructField('pickup_datetime', types.TimestampType(), True)\n",
    "    , types.StructField('dropOff_datetime', types.TimestampType(), True)\n",
    "    , types.StructField('PUlocationID', types.IntegerType(), True)\n",
    "    , types.StructField('DOlocationID', types.IntegerType(), True)\n",
    "    , types.StructField('SR_Flag', types.DoubleType(), True)\n",
    "    , types.StructField('Affiliated_base_number', types.StringType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "af7fdd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= spark.read \\\n",
    "    .option(\"header\",\"True\") \\\n",
    "    .schema(schema=schema) \\\n",
    "    .csv('data/raw/fhv/fhv_tripdata_2019-10.csv.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "29403f74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- dispatching_base_num: string (nullable = true)\n",
      " |-- pickup_datetime: timestamp (nullable = true)\n",
      " |-- dropOff_datetime: timestamp (nullable = true)\n",
      " |-- PUlocationID: integer (nullable = true)\n",
      " |-- DOlocationID: integer (nullable = true)\n",
      " |-- SR_Flag: double (nullable = true)\n",
      " |-- Affiliated_base_number: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "eb123cb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df \\\n",
    "    .repartition(6) \\\n",
    "    .write \\\n",
    "    .parquet('data/pq/fhv/2019/10',mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e09eb609",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf = spark.read.parquet(\"data/pq/fhv/2019/10/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a4a50837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- dispatching_base_num: string (nullable = true)\n",
      " |-- pickup_datetime: timestamp (nullable = true)\n",
      " |-- dropOff_datetime: timestamp (nullable = true)\n",
      " |-- PUlocationID: integer (nullable = true)\n",
      " |-- DOlocationID: integer (nullable = true)\n",
      " |-- SR_Flag: double (nullable = true)\n",
      " |-- Affiliated_base_number: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rdf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "900d5dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf.createOrReplaceTempView('fhv_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2560ac3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trips_15_oct = spark.sql(\"\"\"\n",
    "\n",
    "select count(*) cnt  from fhv_data where cast(pickup_datetime as date) = '2019-10-15'\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "74962693",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 8:=======================================>                   (4 + 2) / 6]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|   62610|\n",
      "+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "trips_15_oct.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "45d292c1",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (1053346520.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_237150/1053346520.py\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    dropOff_datetime,\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "SELECT \n",
    "    dropOff_datetime, \n",
    "    pickup_datetime,\n",
    "    HOUR(FROM_UNIXTIME(UNIX_TIMESTAMP(dropOff_datetime) - UNIX_TIMESTAMP(pickup_datetime))) AS hour_difference\n",
    "FROM \n",
    "    fhv_data \n",
    "LIMIT 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8df4c710",
   "metadata": {},
   "outputs": [],
   "source": [
    "longest_hour = spark.sql(\"\"\"\n",
    "\n",
    "select dropOff_datetime, pickup_datetime,\n",
    "(dropOff_datetime   - pickup_datetime)* 24  AS hour_difference\n",
    "from fhv_data order by 3 desc  limit 1\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c01a6498",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 29:======================================>                   (4 + 2) / 6]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+--------------------+\n",
      "|   dropOff_datetime|    pickup_datetime|     hour_difference|\n",
      "+-------------------+-------------------+--------------------+\n",
      "|2091-10-11 18:30:00|2019-10-11 18:00:00|INTERVAL '631152 ...|\n",
      "+-------------------+-------------------+--------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "longest_hour.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2b80e57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "zones_df = spark.read.csv('data/raw/zones/taxi_zone_lookup.csv', header=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2b427676",
   "metadata": {},
   "outputs": [],
   "source": [
    "zones_df.createOrReplaceTempView('zones')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "61a8011d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+--------------------+------------+\n",
      "|LocationID|      Borough|                Zone|service_zone|\n",
      "+----------+-------------+--------------------+------------+\n",
      "|         1|          EWR|      Newark Airport|         EWR|\n",
      "|         2|       Queens|         Jamaica Bay|   Boro Zone|\n",
      "|         3|        Bronx|Allerton/Pelham G...|   Boro Zone|\n",
      "|         4|    Manhattan|       Alphabet City| Yellow Zone|\n",
      "|         5|Staten Island|       Arden Heights|   Boro Zone|\n",
      "|         6|Staten Island|Arrochar/Fort Wad...|   Boro Zone|\n",
      "|         7|       Queens|             Astoria|   Boro Zone|\n",
      "|         8|       Queens|        Astoria Park|   Boro Zone|\n",
      "|         9|       Queens|          Auburndale|   Boro Zone|\n",
      "|        10|       Queens|        Baisley Park|   Boro Zone|\n",
      "|        11|     Brooklyn|          Bath Beach|   Boro Zone|\n",
      "|        12|    Manhattan|        Battery Park| Yellow Zone|\n",
      "|        13|    Manhattan|   Battery Park City| Yellow Zone|\n",
      "|        14|     Brooklyn|           Bay Ridge|   Boro Zone|\n",
      "|        15|       Queens|Bay Terrace/Fort ...|   Boro Zone|\n",
      "|        16|       Queens|             Bayside|   Boro Zone|\n",
      "|        17|     Brooklyn|             Bedford|   Boro Zone|\n",
      "|        18|        Bronx|        Bedford Park|   Boro Zone|\n",
      "|        19|       Queens|           Bellerose|   Boro Zone|\n",
      "|        20|        Bronx|             Belmont|   Boro Zone|\n",
      "+----------+-------------+--------------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "zones_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "0a57d8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "least_pickup_zone = spark.sql(\"\"\"\n",
    "\n",
    "select Zone,count(*)  \n",
    "from fhv_data a\n",
    "left outer join zones  b on a.PUlocationID = b.LocationID \n",
    "group by Zone order by 2\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "680e2488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+\n",
      "|                Zone|count(1)|\n",
      "+--------------------+--------+\n",
      "|         Jamaica Bay|       1|\n",
      "|Governor's Island...|       2|\n",
      "| Green-Wood Cemetery|       5|\n",
      "|       Broad Channel|       8|\n",
      "|     Highbridge Park|      14|\n",
      "|        Battery Park|      15|\n",
      "|Saint Michaels Ce...|      23|\n",
      "|Breezy Point/Fort...|      25|\n",
      "|Marine Park/Floyd...|      26|\n",
      "|        Astoria Park|      29|\n",
      "|    Inwood Hill Park|      39|\n",
      "|       Willets Point|      47|\n",
      "|Forest Park/Highl...|      53|\n",
      "|  Brooklyn Navy Yard|      57|\n",
      "|        Crotona Park|      62|\n",
      "|        Country Club|      77|\n",
      "|     Freshkills Park|      89|\n",
      "|       Prospect Park|      98|\n",
      "|     Columbia Street|     105|\n",
      "|  South Williamsburg|     110|\n",
      "+--------------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "least_pickup_zone.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64eed82f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
